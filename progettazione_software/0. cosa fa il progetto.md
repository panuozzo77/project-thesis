- Sviluppo di un sistema di raccomandazione libri basato su un dataset Goodreads arricchito tramite fonti legali e aggiornate, con architettura modulare e interfaccia minimale orientata all'utente.
- Il punto focale è la Data Augmentation per prelevare dati di libri più recenti per aggiornare in autonomia i propri dataset

Riduzione FrontEnd | Piano di Data Augmentation | Modello di raccomandazione

- Inizialmente pensavo di sviluppare il sistema sui dati esistenti e di produrre una webapp similare ai competitor (login, raccolta libri, sistema di recensioni, libri consigliati, etc.).
- Ridurre il carico del frontend ad un semplice portale di ricerca dove il generico utente senza alcuna registrazione, inserendo una lista di libri (di suo gradimento) riceve dei libri consigliati.

- Il progetto sarà incentrato sullo sviluppare un sistema che sia in grado di mappare gli attributi raccolti da vari provider (senza scraping ed in maniera legale) per aggiornare la raccolta dei libri, od in un nuovo dataset oppure mantenendo il dataset pre-esistente. 
- Se valido, usando Redis per il caching o delle Code e per l'amministrazione dei dati se l'utente vuole eseguire l'aggiornamento avvalendosi di più computer/esecuzioni concorrenti.
- Architettura modulare che consenta future espansioni senza riprogettazioni radicali

- Il modello di raccomandazione invece impiegherà sia algoritmi collaborativi sia content-based (in assenza di recensioni) noti in letteratura.

---
- Delineerei quindi quali siano le informazioni necessarie per il sistema di raccomandazione da conservare nel dataset.
- Successivamente cercherei come ottenere le nuove informazioni utili sui libri non presenti nel dataset (più recenti o assenti)
	- Permettendo all'utilizzatore di modificare con appositi filtri che tipologia di libri nuovi cercare (per categoria, per anno, per rating, numero di pagine...) Raccogliere tutti i libri risulta essere un lavoro pressoché impossibile. 
	  1) È probabile che non tutti i libri del mondo siano presenti su internet. Cosa non necessaria in quanto un eventuale lettore è interessato principalmente a libri di narrativa e <minimamente> conosciuti.  
		  1) Forse seguendo il principio di Pareto? 20% dei libri più conosciuti = 80% dei libri più letti?
	  2) È molto oneroso in termini di spazio, probabilmente il numero di richieste sarebbe eccessivo
- A questo punto, il sistema di raccomandazione vorrei che funzioni eseguendo prima dei check:
	- 1) Controllare che i libri scelti dall'utente siano parte di collane di libri, in quel caso, è probabile che l'utente sia interessato a leggere il seguito di essi.
	- 2) I nuovi libri scelti dovranno avere un numero di pagine 'in linea' con il numero di pagine che è solito leggere l'utente. Consigliare un libro di 1000 pagine a chi ne legge solitamente 300 potrebbe essere scoraggiante. Questo potrebbe beneficiare la velocità dell'algoritmo, facendo una prima cernita di libri simili
	- 3) Incentivare l'utente ad uscire dal 'guscio' dei propri gusti ed invogliarlo alla lettura di generi che amalgamano i propri interessi in contesti nuovi. Es: Un lettore di sci-fi e gialli potrebbe non trovare interessanti dei libri fantasy come preconcetto, precludendosi la scoperta di altre opere letterarie. È necessario quindi 'scovare' dei libri-ponte che possano far cambiare idea.
		- Difficoltà: il dataset di Goodreads identifica i libri in sole 7 categorie, per me un numero imbarazzante e semplicistico in quanto tanti libri mescolano più generi letterari.