- Sviluppo di un sistema di raccomandazione libri basato su un dataset Goodreads arricchito tramite fonti legali e aggiornate, con architettura modulare e interfaccia minimale orientata all'utente.
- Il punto focale è la Data Augmentation per prelevare dati di libri più recenti per aggiornare in autonomia i propri dataset

Riduzione FrontEnd | Piano di Data Augmentation | Modello di raccomandazione

- Inizialmente pensavo di sviluppare il sistema sui dati esistenti e di produrre una webapp similare ai competitor (login, raccolta libri, sistema di recensioni, libri consigliati, etc.).
- Ridurre il carico del frontend ad un semplice portale di ricerca dove il generico utente senza alcuna registrazione, inserendo una lista di libri (di suo gradimento) riceve dei libri consigliati.

- Il progetto sarà incentrato sullo sviluppare un sistema che sia in grado di mappare gli attributi raccolti da vari provider (senza scraping ed in maniera legale) per aggiornare la raccolta dei libri, od in un nuovo dataset oppure mantenendo il dataset pre-esistente. 
- Architettura modulare che consenta future espansioni senza riprogettazioni radicali

- Il modello di raccomandazione invece impiegherà sia algoritmi collaborativi sia content-based (in assenza di recensioni) noti in letteratura.

---
- Delineerei quindi quali siano le informazioni necessarie per il sistema di raccomandazione da conservare nel dataset.
- Successivamente cercherei come ottenere le nuove informazioni utili sui libri non presenti nel dataset (più recenti o assenti)
	- Permettendo all'utilizzatore di modificare con appositi filtri che tipologia di libri nuovi cercare (per categoria, per anno, per rating, numero di pagine...) Raccogliere tutti i libri risulta essere un lavoro pressoché impossibile. 
	  1) È probabile che non tutti i libri del mondo siano presenti su internet. Cosa non necessaria in quanto un eventuale lettore è interessato principalmente a libri di narrativa e <minimamente> conosciuti.  
		  1) Forse seguendo il principio di Pareto? 20% dei libri più conosciuti = 80% dei libri più letti?
	  2) È molto oneroso in termini di spazio, probabilmente il numero di richieste sarebbe eccessivo
- A questo punto, il sistema di raccomandazione vorrei che funzioni eseguendo prima dei check:
	- 1) Controllare che i libri scelti dall'utente siano parte di collane di libri, in quel caso, è probabile che l'utente sia interessato a leggere il seguito di essi.
	- 2) I nuovi libri scelti dovranno avere un numero di pagine 'in linea' con il numero di pagine che è solito leggere l'utente. Consigliare un libro di 1000 pagine a chi ne legge solitamente 300 potrebbe essere scoraggiante. Questo potrebbe beneficiare la velocità dell'algoritmo, facendo una prima cernita di libri simili
	- 3) Incentivare l'utente ad uscire dal 'guscio' dei propri gusti ed invogliarlo alla lettura di generi che amalgamano i propri interessi in contesti nuovi. Es: Un lettore di sci-fi e gialli potrebbe non trovare interessanti dei libri fantasy come preconcetto, precludendosi la scoperta di altre opere letterarie. È necessario quindi 'scovare' dei libri-ponte che possano far cambiare idea.
		- Difficoltà: il dataset di Goodreads identifica i libri in sole 7 categorie, per me un numero imbarazzante e semplicistico in quanto tanti libri mescolano più generi letterari.


---

Produrre un applicato da CLI che permetta all'utilizzatore, specificando alcuni parametri, diverse azioni:
1) Analizzare le colonne del dataset per comprendere come sono mappati i metadati (titolo, autore...)
2) Aggiornare il dataset (esclusivamente previa analisi delle tabelle al punto precedente)
	- con opportuni filtri ()
3) Produrre ulteriori colonne (forse generando un dataset a parte) contenenti informazioni più specifiche (ad esempio qual è il genere principale e quali altre sfumature di genere presenti nell'opera) utilizzando NLP/AI sull'abstract/sinossi/blurp
4) Interrogare il sistema di raccomandazioni
	- o si espone una pagina web dove l'utente seleziona la lista di libri
	- alternativamente l'utente invia con uno speciale parametro la sua lista di libri presenti su un file di testo/JSON

In maniera modulare lo strumento permette, a scelta:
	- l'impiego di LLM per supportare l'analisi delle intestazioni delle tabelle e la produzione di nuove colonne
	- in assenza di API sfrutta una versione programmatica per eseguire l'analisi dei record o degli headings delle tabelle.

2) Aggiornamento Dataset
	- va considerato un modo efficace per evitare di inserire libri già presenti nel database.
	- è necessario eseguire la pulizia dei dati per ottenere coerenza 

3) 
4) Limitare il sistema di raccomandazioni a qualcosa di più semplice e che sia meno esplorato in letteratura, come:
	- Incentivare l'utente ad uscire dal 'guscio' dei propri gusti ed invogliarlo alla lettura di generi che amalgamano i propri interessi in contesti nuovi. Es: Un lettore di sci-fi e gialli potrebbe non trovare interessanti dei libri fantasy come preconcetto, precludendosi la scoperta di altre opere letterarie. È necessario quindi 'scovare' dei libri-ponte che possano far cambiare idea.
		- Difficoltà: il dataset di Goodreads identifica i libri in sole 7 categorie, per me un numero semplicistico in quanto tanti libri mescolano più generi letterari.
	- Questa limitazione è data dal fatto che è probabile che non riuscirò ad estrarre anche le recensioni automaticamente o che queste possano essere tantissime per alcuni libri (#) e 0 per altri, optando quindi ad un modello di raccomandazione Content Based Filtering piuttosto che Collaborative Filtering [da vedere]
		- #  inoltre, le recensioni nel tempo possono essere modificate ed aggiunte per i libri pre-esistenti, sarebbe un ulteriore aggiornamento davvero oneroso in termini di spazio e tempo.

