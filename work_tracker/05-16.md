Buon pomeriggio Prof, ecco il riassunto settimanale
    12 Maggio: Ho iniziato analizzando l'approccio del dataset goodreads_bbe_dataset. Ho esaminato come hanno costruito la loro lista dei "Best Books Ever" tramite le votazioni degli utenti di Goodreads e come hanno poi utilizzato uno script Python per estrarre le informazioni dai singoli libri. Ho anche notato che questo metodo, sebbene non legalmente vincolante, viola i Termini di Servizio di Goodreads (come immaginavo).

    13 e 14 Maggio: Mi sono concentrato sull'analisi del codice del repository precedente con l'obiettivo di aggiornarlo per l'estrazione delle informazioni dei libri. Al momento, sono riuscito a recuperare la lista dei link ai libri, ma non sono ancora riuscito ad estrarre i dettagli desiderati. Purtroppo, ho riscontrato che il codice è deprecato a causa dei cambiamenti nelle librerie Python e nella struttura del sito web di Goodreads negli ultimi cinque anni. L'HTML del sito è cambiato significativamente, rendendo necessaria una revisione completa del processo di scraping.

    15 Maggio: Ho dedicato la giornata alla stesura delle porzioni iniziali della tesi e alla definizione più precisa del progetto software che intendo sviluppare.

    16 Maggio: Ho abbozzato le parti iniziali della tesi
    Non è ancora in uno stato re-visionabile, credo che entro metà della prossima settimana potrebbe diventarlo.
    
    Parallelamente, ho continuato a definire le funzionalità dell'applicazione da CLI che intendo sviluppare, focalizzandomi sui seguenti aspetti:
        Analisi delle colonne del dataset per la comprensione dei metadati (per il funzionamento su qualsiasi dataset librario).
        Aggiornamento del dataset con filtri, gestendo l'inserimento di nuovi libri ed effettuando la pulizia dei dati.
        Produzione di nuove colonne con informazioni specifiche sui generi tramite NLP/AI sugli abstract.
        Implementazione di un sistema di raccomandazione che, data la potenziale difficoltà nell'ottenere recensioni complete, si concentrerà sull'incentivare l'utente a esplorare generi nuovi, partendo dai suoi interessi, identificando "libri-ponte".

    L'applicazione sarà modulare e permetterà l'uso opzionale di LLM per l'analisi dei dati.

Nei prossimi giorni, continuerò a lavorare sulla progettazione del sistema e credo di chiedere un parere in merito.
---

abbozzato le parti iniziali della tesi
Indice
1 Introduzione 1
1.1 Contesto Applicativo . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Motivazioni e obiettivi . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.3 Risultati ottenuti . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.4 Struttura Tesi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
2 Background e Stato dell’Arte 4
2.1 Cos’è un libro? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
2.2 Algoritmi di Raccomandazione . . . . . . . . . . . . . . . . . . . . . . 5
2.2.1 Content-Based Filtering . . . . . . . . . . . . . . . . . . . . . . 5
2.2.2 Collaborative Filtering . . . . . . . . . . . . . . . . . . . . . . . 5
2.3 Piattaforme di Raccomandazione Esistenti . . . . . . . . . . . . . . . . 6
2.3.1 Goodreads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.3.2 TheStoryGraph . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.4 Data Augmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.4.1 Obiettivi e Benefici . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.4.2 Approcci . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
i
Indice
2.4.3 nota sulla difficoltà . . . . . . . . . . . . . . . . . . . . . . . . . 9
3 Metodo di Ricerca 12
4 Conclusioni 16
Bibliografia 17

Produrre un applicato da CLI che permetta all'utilizzatore, specificando alcuni parametri, diverse azioni:
1) Analizzare le colonne del dataset per comprendere come sono mappati i metadati (titolo, autore...)
2) Aggiornare il dataset (esclusivamente previa analisi delle tabelle al punto precedente)
	- con opportuni filtri ()
3) Produrre ulteriori colonne (forse generando un dataset a parte) contenenti informazioni più specifiche (ad esempio qual è il genere principale e quali altre sfumature di genere presenti nell'opera) utilizzando NLP/AI sull'abstract/sinossi/blurp
4) Interrogare il sistema di raccomandazioni
	- o si espone una pagina web dove l'utente seleziona la lista di libri
	- alternativamente l'utente invia con uno speciale parametro la sua lista di libri presenti su un file di testo/JSON

In maniera modulare lo strumento permette, a scelta:
	- l'impiego di LLM per supportare l'analisi delle intestazioni delle tabelle e la produzione di nuove colonne
	- in assenza di API sfrutta una versione programmatica per eseguire l'analisi dei record o degli headings delle tabelle.

2) Aggiornamento Dataset
	- va considerato un modo efficace per evitare di inserire libri già presenti nel database.
	- è necessario eseguire la pulizia dei dati per ottenere coerenza 

3) 
4) Limitare il sistema di raccomandazioni a qualcosa di più semplice e che sia meno esplorato in letteratura, come:
	- Incentivare l'utente ad uscire dal 'guscio' dei propri gusti ed invogliarlo alla lettura di generi che amalgamano i propri interessi in contesti nuovi. Es: Un lettore di sci-fi e gialli potrebbe non trovare interessanti dei libri fantasy come preconcetto, precludendosi la scoperta di altre opere letterarie. È necessario quindi 'scovare' dei libri-ponte che possano far cambiare idea.
		- Difficoltà: il dataset di Goodreads identifica i libri in sole 7 categorie, per me un numero semplicistico in quanto tanti libri mescolano più generi letterari.
	- Questa limitazione è data dal fatto che è probabile che non riuscirò ad estrarre anche le recensioni automaticamente o che queste possano essere tantissime per alcuni libri (#) e 0 per altri, optando quindi ad un modello di raccomandazione Content Based Filtering piuttosto che Collaborative Filtering [da vedere]
		- (#)  inoltre, le recensioni nel tempo possono essere modificate ed aggiunte per i libri pre-esistenti, sarebbe un ulteriore aggiornamento davvero oneroso in termini di spazio e tempo.
		- 